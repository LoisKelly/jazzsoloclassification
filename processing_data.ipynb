{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data\n",
    "\n",
    "Here I am preprocessing the data for the audio classifier. \n",
    "\n",
    "It includes:\n",
    "\n",
    "- Converting the midi files from https://jazzomat.hfm-weimar.de/dbformat/dbcontent.html into WAV files. \n",
    "- Sorting the files into folders for each artist. \n",
    "- Splitting the files into 5 second segments and saving them with the same names in the same respective sub folders. \n",
    "\n",
    "I had lots of help writing this code from Louie and LLM models. \n",
    "\n",
    "Code: \n",
    "- https://github.com/JinayJain/timidity\n",
    "- https://stackoverflow.com/questions/60105626/split-audio-on-timestamps-librosa \n",
    "\n",
    "DUE TO FOLDER SIZE CONSTRAINTS PLEASE FIND AND DOWNLOAD THE DATA FILES HERE:\n",
    "https://drive.google.com/drive/folders/1q7doAYmSEUWp3-QPFnOoosSbLZHpmVnC?usp=sharing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting MIDI files to WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://github.com/JinayJain/timidity and help from Louis! \n",
    "# Converting MIDI files into WAV files. \n",
    "# https://stackoverflow.com/questions/10989005/do-i-understand-os-walk-right\n",
    "from timidity import Parser, play_notes\n",
    "from scipy.signal import square, sawtooth\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import os.path\n",
    "\n",
    "for path, directories, files in os.walk('/Users/loiskelly/Documents/GitHub/ai4mediaproject/data/jazz_solos'):\n",
    "     for file in files:\n",
    "        try:\n",
    "            midi_file_path = os.path.join(path, file)\n",
    "            ps = Parser(midi_file_path)\n",
    "            audio, player = play_notes(*ps.parse(), np.sin, wait_done=False)\n",
    "            wavfile.write(f\"{file}.wav\", 44100, audio)\n",
    "            # player.wait_done()\n",
    "        except Exception as e: \n",
    "            print(e) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving files into class folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code was written by ChatGTP. Due to how much time I had already spent sourcing this data I didn't want to waste more \n",
    "# working out how to do this! \n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def move_wav_files(source_folder, destination_folder):\n",
    "    # Get a list of all files in the source folder\n",
    "    files = os.listdir(source_folder)\n",
    "\n",
    "    # Create a dictionary to store files based on common prefixes\n",
    "    file_dict = {}\n",
    "\n",
    "    # Iterate through each file in the source folder\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):\n",
    "            # Extract the common prefix up to the underscore\n",
    "            prefix = file.split(\"_\")[0]\n",
    "\n",
    "            # If the prefix is not in the dictionary, create a new list for it\n",
    "            if prefix not in file_dict:\n",
    "                file_dict[prefix] = []\n",
    "\n",
    "            # Add the file to the list associated with its prefix\n",
    "            file_dict[prefix].append(file)\n",
    "\n",
    "    # Iterate through the dictionary and move files to new folders\n",
    "    for prefix, files_list in file_dict.items():\n",
    "        folder_path = os.path.join(destination_folder, prefix)\n",
    "\n",
    "        # Create the folder if it doesn't exist\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "        # Move each file to its respective folder\n",
    "        for file in files_list:\n",
    "            source_path = os.path.join(source_folder, file)\n",
    "            destination_path = os.path.join(folder_path, file)\n",
    "            shutil.move(source_path, destination_path)\n",
    "            print(f\"Moved '{file}' to '{folder_path}'\")\n",
    "\n",
    "# Example usage:\n",
    "source_folder = \"/Users/loiskelly/Documents/GitHub/ai4mediaproject/data/wav_files\"\n",
    "destination_folder = \"/Users/loiskelly/Documents/GitHub/ai4mediaproject/data/wav_folders\"\n",
    "\n",
    "move_wav_files(source_folder, destination_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Book{Pfleiderer:2017:BOOK,\n",
    "#   title =     {{I}nside the {J}azzomat - {N}ew {P}erspectives for {J}azz  {R}esearch},\n",
    "#   publisher = {Schott Campus},\n",
    "#   year =      {2017},\n",
    "#   editor =    {Pfleiderer, Martin and Frieler, Klaus and Abe{\\ss}er, Jakob and Zaddach, Wolf-Georg and Burkhart, Benjamin},\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import imageio_ffmpeg as ffmpeg\n",
    "import librosa \n",
    "\n",
    "# Code is from https://stackoverflow.com/questions/60105626/split-audio-on-timestamps-librosa \n",
    "\n",
    "# First load the file\n",
    "audio, sr = librosa.load('/Users/loiskelly/Documents/GitHub/ai4mediaproject/data/jazz_solos/Art_Pepper/ArtPepper_Anthropology_FINAL.wav')\n",
    "# Get number of samples for 2 seconds; replace 2 by any number\n",
    "buffer = 30 * sr\n",
    "\n",
    "samples_total = len(audio)\n",
    "samples_wrote = 0\n",
    "counter = 1\n",
    "while samples_wrote < samples_total:\n",
    "    #check if the buffer is not exceeding total samples \n",
    "    if buffer > (samples_total - samples_wrote):\n",
    "        buffer = samples_total - samples_wrote\n",
    "    block = audio[samples_wrote : (samples_wrote + buffer)]\n",
    "    out_filename = \"split_\" + str(counter) + \"_\" + file_name\n",
    "    # Write 2 second segment\n",
    "    librosa.soundfile.write(out_filename, block, sr)\n",
    "    counter += 1\n",
    "    samples_wrote += buffer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into 5 second splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import os \n",
    "import os, sys\n",
    "\n",
    "\n",
    "window_size = 1024 \n",
    "\n",
    "# This code is from https://stackoverflow.com/questions/60105626/split-audio-on-timestamps-librosa\n",
    "# With help from ChatGTP \n",
    "def split_and_save(audio_path, output_folder, duration=30):\n",
    "    audio_data, sr = librosa.load(audio_path, sr=None)\n",
    "    total_segments = int(np.ceil(len(audio_data) / (duration * sr)))\n",
    "\n",
    "    for i in range(total_segments):\n",
    "        start_sample = i * duration * sr\n",
    "        end_sample = min((i + 1) * duration * sr, len(audio_data))\n",
    "        segment = audio_data[start_sample:end_sample]\n",
    "        windows = librosa.util.frame(segment, frame_length=window_size)\n",
    "        windows = windows.transpose()\n",
    "        amps = []\n",
    "        for buffer in windows:\n",
    "            mean = np.abs(buffer.mean())\n",
    "            amps.append(mean)\n",
    "        plt.plot(amps)\n",
    "\n",
    "        # Save the segment with the same filename and a segment number\n",
    "        filename = os.path.join(output_folder, f\"{os.path.basename(audio_path)}_{i + 1}.wav\")\n",
    "        librosa.output.write_wav(filename, segment, sr)\n",
    "\n",
    "input_folder = \"/Users/loiskelly/Documents/GitHub/ai4mediaproject/data/Jazz_solo_testing_data\"\n",
    "output_folder = \"/Users/loiskelly/Documents/GitHub/ai4mediaproject/data/Jazz_solo_testing_data_split\"\n",
    "\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"): \n",
    "            audio_path = os.path.join(root, file)\n",
    "            split_and_save(audio_path, output_folder, duration=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features\n",
    "This code extracts the features of the audio files using librose. I was going to use this to build a simpiler classification model and compare however due to time constraints I didn't make it this far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code written with help from Louie \n",
    "\n",
    "#This is the label you learn (added as last feature, split off to use a y, other features are X)\n",
    "\n",
    "window_seconds = 5\n",
    "features = []\n",
    "key = [[]]\n",
    "label = 0\n",
    "for folder, directory, files in os.walk('/Users/loiskelly/Documents/GitHub/ai4mediaproject/data/wav_folders'):\n",
    "    artist = os.path.basename(folder)\n",
    "    for i in files:\n",
    "        file_path = os.path.join(folder, i)\n",
    "        audio_data, sr = librosa.load(file_path)\n",
    "        window_size = sr*window_seconds\n",
    "        windows = librosa.util.frame(audio_data, frame_length=window_size, hop_length=window_size)\n",
    "        windows = windows.transpose()\n",
    "        for buffer in windows:\n",
    "            chroma = librosa.feature.chroma_stft(y = buffer)\n",
    "            chroma = list(chroma.mean(axis=1))\n",
    "            chroma.append((buffer**2).mean())\n",
    "            features.append(chroma + [label])\n",
    "    \n",
    "    key.append(artist + [label])\n",
    "    label += 1\n",
    "\n",
    "features = np.array(features)\n",
    "features.shape\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing files that aren't the same length\n",
    "\n",
    "This code was written with help LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "\n",
    "def remove_short_files(root_dir):\n",
    "    #Walking through the folder\n",
    "    for root, _, files in os.walk(root_dir):  \n",
    "        for file in files:\n",
    "            #Find the audio files\n",
    "            if file.endswith(\".wav\"): \n",
    "                file_path = os.path.join(root, file)\n",
    "                duration = librosa.get_duration(filename=file_path) \n",
    "                if duration < 5: \n",
    "                        # Remove them if they aren't 5 seconds long \n",
    "                        os.remove(file_path)  \n",
    "\n",
    "# Example usage:\n",
    "root_dir = \"/Users/loiskelly/Documents/GitHub/ai4mediaproject/data/wav_folders_split\"  \n",
    "remove_short_files(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spectograms\n",
    "\n",
    "This code is from https://github.com/nicknochnack/DeepAudioClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SPECTROGRAM_DPI = 90\n",
    "DEFAULT_SAMPLE_RATE = 44100\n",
    "DEFAULT_HOPE_LENGTH = 1024\n",
    "\n",
    "class Audio:\n",
    "    def __init__(self, filepath, hop_length=DEFAULT_HOPE_LENGTH, sample_rate=DEFAULT_SAMPLE_RATE):\n",
    "        self.hop_length = hop_length\n",
    "        self.sample_rate = sample_rate\n",
    "        self.waveform, self.sample_rate = torchaudio.load(filepath)\n",
    "\n",
    "    def plot_spectrogram(self):\n",
    "        waveform = self.waveform.numpy()\n",
    "        _, axes = plt.subplots(1, 1)\n",
    "        axes.specgram(waveform[0], Fs=self.sample_rate)\n",
    "        plt.axis('off')\n",
    "        plt.show(block=False)\n",
    "    \n",
    "    def write_disk_spectrogram(self, path, dpi=SPECTROGRAM_DPI):\n",
    "        self.plot_spectrogram()\n",
    "        plt.savefig(path, dpi=dpi, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "input_folder = \"/Users/loiskelly/Documents/GitHub/ai4mediaproject/data/wav_folders_split\"\n",
    "output_folder = \"/Users/loiskelly/Documents/GitHub/ai4mediaproject/data/wav_split_specto\"\n",
    "\n",
    "for folder, _, files in os.walk(input_folder):\n",
    "    for i, file in enumerate(files):\n",
    "        file_path = os.path.join(folder, file)\n",
    "        artist = os.path.basename(folder)\n",
    "        output_path = os.path.join(output_folder, f\"{artist}_{i + 1}.png\")\n",
    "        \n",
    "        # Create the output folder if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        sound = Audio(file_path)\n",
    "        sound.write_disk_spectrogram(output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
